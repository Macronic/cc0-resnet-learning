{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137b5474-34a9-4580-9da1-2845a38ddc10",
   "metadata": {},
   "source": [
    "# J. Paul Getty Museum Collection Download\n",
    "The museum is sharing an art collection dataset with some CC0 license, what we can use to train our CC0 ResNet backbone for other projects!\n",
    "Their docs page: https://data.getty.edu/museum/collection/docs/ contains documentation how to download the images from their API.\n",
    "We can use the image as long as it has a valid '\"id\": \"https://creativecommons.org/publicdomain/zero/1.0/\"' field in its data, what we will filter on. The dataset may contain up to 150000 objects, and we will need a lot of that to train a ResNet backbone that would have transferable knowledge.\n",
    "\n",
    "Note that their API is just awful, SPARQL is time outing all the time, there's no way to just get object IDs. Fortunately, Activity stream has links to most of them, so we scrap it from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969e9ce-eba1-4354-b7d9-b7142f855395",
   "metadata": {},
   "source": [
    "### Constants and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05091c7-2b58-4635-a6c8-a36c56cfd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from atomicwrites import atomic_write\n",
    "import rdflib\n",
    "\n",
    "BASE_METADATA_URL = 'https://data.getty.edu/museum/collection/object'\n",
    "ACTIVITY_STREAM_URL = 'https://data.getty.edu/museum/collection/activity-stream/page'\n",
    "CC0_IDENTIFIER = 'http://creativecommons.org/publicdomain/zero/1.0/'\n",
    "METADATA_DIRECTORY = 'metadata'\n",
    "DATASET_NAME = 'get'\n",
    "RAW_IMAGE_DIRECTORY = os.path.join('dataset', 'raw')\n",
    "DATASET_IMAGES_LIMIT = 70000\n",
    "DATASET_IDS_LIMIT = 150000\n",
    "IMAGE_WIDTH = 843\n",
    "ID_DOWNLOADING_SAVE_PERIOD = 10\n",
    "METADATA_DOWNLOADING_SAVE_PERIOD = 30\n",
    "METADATA_PARSING_SAVE_PERIOD = 200\n",
    "ACCEPT = \"application/json\"\n",
    "ACCEPT_LANGUAGE = \"en-US,en;q=0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35dc6e-77a9-44ae-8a9e-f6a9a6e307f5",
   "metadata": {},
   "source": [
    "### Preparing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70fb961-5fb5-402b-96c0-2b7407b685f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RAW_IMAGE_DIRECTORY):\n",
    "    os.makedirs(RAW_IMAGE_DIRECTORY)\n",
    "    \n",
    "if not os.path.exists(METADATA_DIRECTORY):\n",
    "    os.makedirs(METADATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7690eb-1d4b-46d9-aa04-59723ad08b93",
   "metadata": {},
   "source": [
    "### Checking existing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db10c1af-4b81-4b96-9dcc-8c7f7221b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_metadata = {}\n",
    "object_ids = set()\n",
    "raw_metadata = {}\n",
    "current_page = 1\n",
    "\n",
    "BASIC_METADATA_PATH = os.path.join(METADATA_DIRECTORY, f'{DATASET_NAME}.json')\n",
    "RAW_METADATA_PATH = os.path.join(METADATA_DIRECTORY, f'{DATASET_NAME}-raw.json')\n",
    "OBJECT_IDS_PATH = os.path.join(METADATA_DIRECTORY, f'{DATASET_NAME}-ids.json')\n",
    "\n",
    "if os.path.exists(BASIC_METADATA_PATH):\n",
    "    with open(BASIC_METADATA_PATH, 'r') as f:\n",
    "        existing_metadata = json.load(f)\n",
    "\n",
    "if os.path.exists(RAW_METADATA_PATH):\n",
    "    with open(RAW_METADATA_PATH, 'r') as f:\n",
    "        raw_metadata = json.load(f)\n",
    "\n",
    "if os.path.exists(OBJECT_IDS_PATH):\n",
    "    with open(OBJECT_IDS_PATH, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        object_ids = set(data['object_ids'])\n",
    "        current_page = data['current_page']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f167cdc7-a71f-4aee-ba50-2f42e92ef53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata():\n",
    "    with atomic_write(BASIC_METADATA_PATH, overwrite=True) as f:\n",
    "        json.dump(existing_metadata, f, default=str)\n",
    "\n",
    "def save_raw_metadata():\n",
    "    with atomic_write(RAW_METADATA_PATH, overwrite=True) as f:\n",
    "        json.dump(raw_metadata, f)\n",
    "\n",
    "def save_object_ids():\n",
    "    with atomic_write(OBJECT_IDS_PATH, overwrite=True) as f:\n",
    "        json.dump({'object_ids': list(object_ids), 'current_page': current_page}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f5ff1a-1c96-471f-9588-2750b145e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(value):\n",
    "    return value.split('/')[6].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eadca95-7368-4f5d-8d78-fa2969daa19c",
   "metadata": {},
   "source": [
    "### Iterate through the activity stream, gathering object ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ecd766a-d4e3-431e-9fb3-10de57646eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d):\n",
    "    for i in getattr(d, 'values', lambda :d)():\n",
    "        if isinstance(i, str):\n",
    "            yield i\n",
    "        elif i is not None and isinstance(i, (dict, list)):\n",
    "            yield from flatten(i)\n",
    "\n",
    "def gather_object_ids(data):\n",
    "    possible_ids = flatten(data)\n",
    "    for value in possible_ids:\n",
    "        if BASE_METADATA_URL in value:\n",
    "            id = extract_id(value)\n",
    "            object_ids.add(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "381f204b-1540-4df9-8c34-067e63a56e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd32d725a2ca45c7b8f8b1e618367636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_object_ids_length = len(object_ids)\n",
    "page_limit = 39181 # Taken from https://data.getty.edu/museum/collection/activity-stream\n",
    "\n",
    "with tqdm(total=DATASET_IDS_LIMIT) as pbar:\n",
    "    while current_page < page_limit and DATASET_IDS_LIMIT > len(object_ids):\n",
    "        try:\n",
    "            url = f'{ACTIVITY_STREAM_URL}/{current_page}'\n",
    "            data = requests.get(url, headers={'Accept': ACCEPT,  \"Accept-Language\": ACCEPT_LANGUAGE })\n",
    "            data = data.json()\n",
    "            gather_object_ids(data)\n",
    "    \n",
    "            current_page += 1\n",
    "            \n",
    "            if len(object_ids) - last_object_ids_length >= ID_DOWNLOADING_SAVE_PERIOD:\n",
    "                save_object_ids()\n",
    "                last_object_ids_length = len(object_ids)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Failed at url \"{url}\" - {e}')\n",
    "        pbar.update(len(object_ids) - pbar.n)\n",
    "        pbar.set_description(f'current_page={current_page}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80039cb-b2d5-4004-bc75-b83dbd14cdbe",
   "metadata": {},
   "source": [
    "### Gather metadata and images for the scraped IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45673c6-ed46-47c3-bfcc-fa6b204faa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, path):\n",
    "    if os.path.exists(path):\n",
    "        return\n",
    "    image_data = requests.get(url, stream=True)\n",
    "    if image_data.status_code == 200:\n",
    "        with atomic_write(path, overwrite=True, mode='wb') as f:\n",
    "            for chunk in image_data.iter_content(2048):\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8495012-bde5-467b-ba40-4d781842d565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58da830b05f41f1affa4f4d18b9d998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156511 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_metadata_length = len(raw_metadata)\n",
    "\n",
    "def find_id_in(array, id):\n",
    "    for a in array:\n",
    "        if 'id' in a and a['id'] == id:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "downloaded_images = 0\n",
    "for id in raw_metadata:\n",
    "    if 'path' in raw_metadata[id]:\n",
    "        downloaded_images += 1\n",
    "\n",
    "with tqdm(total=len(object_ids)) as pbar:\n",
    "    for id in sorted(list(object_ids)):\n",
    "        try:\n",
    "            if id in raw_metadata:\n",
    "                pbar.update(len(raw_metadata) - pbar.n)\n",
    "                continue\n",
    "            url = f'{BASE_METADATA_URL}/{id}'\n",
    "            data = requests.get(url, headers={'Accept': ACCEPT,  \"Accept-Language\": ACCEPT_LANGUAGE })\n",
    "            data = data.json()\n",
    "            if 'shows' not in data or len(data['shows']) < 1 or 'id' not in data['shows'][0]:\n",
    "                raw_metadata[id] = { 'unavailable': True }\n",
    "                continue\n",
    "    \n",
    "            media_url = data['shows'][0]['id']\n",
    "            image_data = requests.get(media_url, headers={'Accept': ACCEPT,  \"Accept-Language\": ACCEPT_LANGUAGE }).json()\n",
    "\n",
    "            if 'subject_to' not in image_data or image_data['subject_to'][0]['classified_as'][0]['id'] != CC0_IDENTIFIER:\n",
    "                raw_metadata[id] = { 'unavailable': True }\n",
    "                continue\n",
    "\n",
    "            path = os.path.join(RAW_IMAGE_DIRECTORY, f'get_{id}.jpg')\n",
    "\n",
    "            image_download_url = image_data['digitally_shown_by'][0]['access_point'][0]['id']\n",
    "            \n",
    "            download_image(f'{image_download_url}/full/!{IMAGE_WIDTH},/0/default.jpg', path)\n",
    "\n",
    "            data['image_data'] = image_data\n",
    "            data['path'] = path\n",
    "            raw_metadata[id] = data\n",
    "            downloaded_images += 1\n",
    "            if len(raw_metadata) - last_metadata_length >= METADATA_DOWNLOADING_SAVE_PERIOD:\n",
    "                save_raw_metadata()\n",
    "                last_metadata_length = len(raw_metadata)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Failed at url \"{url}\" - {e}')\n",
    "        pbar.update(len(raw_metadata) - pbar.n)\n",
    "        pbar.set_description(f'images={downloaded_images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152dced2-d234-4c03-b6b8-077ee173b587",
   "metadata": {},
   "source": [
    "### Processing the metadata file to ready the data, as parsing it takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1af97-796f-4f60-b8d9-812885fee0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAS_CONTENT = '<http://www.cidoc-crm.org/cidoc-crm/P190_has_symbolic_content>'\n",
    "HAS_LABEL = '<http://www.w3.org/2000/01/rdf-schema#label>'\n",
    "HAS_BEGIN_DATE = '<http://www.cidoc-crm.org/cidoc-crm/P82a_begin_of_the_begin>'\n",
    "HAS_END_DATE = '<http://www.cidoc-crm.org/cidoc-crm/P82b_end_of_the_end>'\n",
    "\n",
    "IS_OF_TYPE = '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>'\n",
    "CLASSIFIED_AS = '<http://www.cidoc-crm.org/cidoc-crm/P2_has_type>'\n",
    "IDENTIFIED_BY = '<http://www.cidoc-crm.org/cidoc-crm/P1_is_identified_by>'\n",
    "CURRENT_KEEPER = '<http://www.cidoc-crm.org/cidoc-crm/P50_has_current_keeper>'\n",
    "\n",
    "CREDIT_LINE = '<http://vocab.getty.edu/aat/300435418>'\n",
    "WORK_TYPE = '<http://vocab.getty.edu/aat/300435443>'\n",
    "MATERIALS_DESCRIPTION = '<http://vocab.getty.edu/aat/300435429>'\n",
    "TIMESPAN = '<http://www.cidoc-crm.org/cidoc-crm/E52_Time-Span>'\n",
    "\n",
    "last_metadata_length = len(existing_metadata)\n",
    "\n",
    "def get_first(data, query):\n",
    "    for p, in data.query(query):\n",
    "        return p.toPython()\n",
    "    return None\n",
    "\n",
    "for id in tqdm(raw_metadata):\n",
    "    if id in existing_metadata:\n",
    "        continue\n",
    "    if 'unavailable' in raw_metadata[id]:\n",
    "        existing_metadata[id] = { 'unavailable': True }\n",
    "        continue\n",
    "\n",
    "    entry = {}\n",
    "    data = rdflib.Graph().parse(data=json.dumps(raw_metadata[id]), format=\"json-ld\")\n",
    "    entry['id'] = id\n",
    "    entry['title'] = raw_metadata[id]['_label']\n",
    "    entry['type'] = get_first(data, f\"SELECT DISTINCT ?content WHERE {{ ?sub {CLASSIFIED_AS} {WORK_TYPE} . ?sub {HAS_CONTENT} ?content . }} \")\n",
    "    entry['path'] = raw_metadata[id]['path']\n",
    "    entry['department'] = get_first(data, f\"SELECT DISTINCT ?label WHERE {{ ?sub {CURRENT_KEEPER} ?sub2 . ?sub2 {HAS_LABEL} ?label . }} \")\n",
    "    entry['collection'] = get_first(data, f\"SELECT DISTINCT ?content WHERE {{ ?sub {CLASSIFIED_AS} {CREDIT_LINE} . ?sub {HAS_CONTENT} ?content . }} \")\n",
    "    entry['culture'] = get_first(data, f\"SELECT DISTINCT ?content WHERE {{ ?sub {HAS_LABEL} \\\"Culture Statement\\\" . ?sub {HAS_CONTENT} ?content . }} \")\n",
    "    entry['technique'] = get_first(data, f\"SELECT DISTINCT ?content WHERE {{ ?sub {CLASSIFIED_AS} {MATERIALS_DESCRIPTION} . ?sub {HAS_CONTENT} ?content . }} \")\n",
    "                \n",
    "    entry['date'] = get_first(data, f\"SELECT DISTINCT ?content WHERE {{ ?sub {IS_OF_TYPE} {TIMESPAN} . ?sub {IDENTIFIED_BY} ?sub2 . ?sub2 {HAS_CONTENT} ?content . }} \")\n",
    "    entry['begin_date'] = get_first(data, f\"SELECT DISTINCT ?date WHERE {{ ?sub {IS_OF_TYPE} {TIMESPAN} . ?sub {HAS_BEGIN_DATE} ?date . }} \")\n",
    "    entry['end_date'] = get_first(data, f\"SELECT DISTINCT ?date WHERE {{ ?sub {IS_OF_TYPE} {TIMESPAN} . ?sub {HAS_END_DATE} ?date . }} \")\n",
    "    existing_metadata[id] = entry\n",
    "\n",
    "    if len(existing_metadata) - last_metadata_length >= METADATA_PARSING_SAVE_PERIOD:\n",
    "        save_metadata()\n",
    "        last_metadata_length = len(existing_metadata)\n",
    "        \n",
    "save_metadata()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3e8b7-4c02-46bc-b372-12a8197de535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
