{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d4e08b-4dfa-4b9e-9758-59de882868d3",
   "metadata": {},
   "source": [
    "# ResNet-50 Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448494bc-15a3-4bfe-a164-a27aedb00d84",
   "metadata": {},
   "source": [
    "Time to put our dataset to use! We'll use pytorch-lightning as a trainer!\n",
    "\n",
    "If you'd like to see, how well does the backbone work compared to using transfer with the main article ResNet-50, see ResNet-50 Backbone Testing notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f1740-3385-4734-86fb-4e846741fdc7",
   "metadata": {},
   "source": [
    "### Constants and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c7b8be-d30f-421d-acc1-93fc1c607ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightning.pytorch import Trainer, seed_everything, LightningModule\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from safetensors.torch import save_model\n",
    "import json\n",
    "\n",
    "METADATA_DIRECTORY = 'metadata'\n",
    "USE_PREPROCESSED_IMAGES = True\n",
    "DATASET_FILE = os.path.join(METADATA_DIRECTORY, 'dataset-preprocessed.csv') if USE_PREPROCESSED_IMAGES else os.path.join(METADATA_DIRECTORY, 'dataset.csv')\n",
    "CHECKPOINTS_DIRECTORY = 'checkpoints'\n",
    "LOAD_LAST_CHECKPOINT = False\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba1d87-40de-41df-8440-d3d3ec9716dc",
   "metadata": {},
   "source": [
    "### Preparing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce170fd-29fb-4581-a188-7c16ec1f69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CHECKPOINTS_DIRECTORY):\n",
    "    os.makedirs(CHECKPOINTS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bb0ac-facd-41f6-8531-2e00b22ac435",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe169f99-8434-4047-8c48-29db5eec09c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_111361/1652983266.py:1: DtypeWarning: Columns (4,5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATASET_FILE)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FILE)\n",
    "\n",
    "classes = sorted(pd.unique(df['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a0df5e-e87b-48e3-9edd-5361cb6c80c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8a0031b-7197-480b-b629-144c87bd4b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318563"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994bfa2-8809-4686-a9cb-f533da7e359d",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d356b918-c254-44f4-9361-c36f3f28687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['path'], df['class'], test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7abad0-725b-42be-9dbc-cec21444cc63",
   "metadata": {},
   "source": [
    "### Define transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed28eff-c460-48cf-8f02-572d2906e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.2),\n",
    "    v2.RandomRotation(5),\n",
    "    v2.Resize(size=(224, 224), antialias=True),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05)\n",
    "])\n",
    "\n",
    "test_transforms = v2.Compose([\n",
    "    v2.Resize(size=(224, 224), antialias=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495a743-4f10-4616-834c-2f0c824da225",
   "metadata": {},
   "source": [
    "### Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14f1d22-630e-4b1f-b7d6-3ad4e859f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuseumCC0Dataset(Dataset):\n",
    "    def __init__(self, Xs, ys, transform=None):\n",
    "        self.Xs = list(Xs)\n",
    "        self.ys = torch.tensor([classes.index(y) for y in ys])\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = read_image(self.Xs[idx])\n",
    "\n",
    "        image = image.float() / 255\n",
    "\n",
    "        if image.size()[0] == 1:\n",
    "            image = image.repeat(3, 1, 1)\n",
    "\n",
    "        if image.size()[0] == 4:\n",
    "            image = image[1:4]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.ys[idx]\n",
    "\n",
    "train_dataset = MuseumCC0Dataset(X_train, y_train, train_transforms)\n",
    "test_dataset = MuseumCC0Dataset(X_test, y_test, test_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=5)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b6ca9-d260-4792-9dfd-7b138326cb6c",
   "metadata": {},
   "source": [
    "### Creating the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "917b9594-582d-4015-b232-d66138956e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "class MuseumCC0Module(torch.nn.Module, PyTorchModelHubMixin):\n",
    "    def __init__(self, classes_count):\n",
    "        super().__init__()\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights=None)\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, classes_count)\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "                               \n",
    "class MuseumCC0LightningModule(LightningModule, PyTorchModelHubMixin):\n",
    "    def __init__(self, classes_count):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = MuseumCC0Module(classes_count)\n",
    "        self.loss_module = torch.nn.CrossEntropyLoss()\n",
    "        sd = self.state_dict()\n",
    "        sd[\"metadata\"] = {\"format\": \"pt\"}\n",
    "        \n",
    "\n",
    "    def forward(self, imgs):\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.1 ** (epoch // 30))\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = self.model(images)\n",
    "        \n",
    "        loss = self.loss_module(preds, labels)\n",
    "\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        preds = self.model(images)\n",
    "\n",
    "        loss = self.loss_module(preds, labels)\n",
    "\n",
    "        acc = (labels == preds.argmax(dim=-1)).float().mean()\n",
    "\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def _save_pretrained(self, save_directory) -> None:\n",
    "        model_to_save = self.module if hasattr(self, \"module\") else self \n",
    "        save_model(model_to_save, str(save_directory / \"model.safetensors\"), {\"format\": \"pt\"})\n",
    "\n",
    "trainer = Trainer(default_root_dir=CHECKPOINTS_DIRECTORY, max_epochs=EPOCH_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55697927-ec9c-40e0-b2cf-6ab37f06830d",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236c55cf-165e-4f6d-a9b0-f7ab6a737e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newest_model():\n",
    "    logs_paths = os.path.join(CHECKPOINTS_DIRECTORY, 'lightning_logs')\n",
    "    newest_version = -1\n",
    "    checkpoint_path = None\n",
    "    for dir in os.listdir(logs_paths):\n",
    "        dir_path = os.path.join(logs_paths, dir)\n",
    "        if os.path.isdir(dir_path) and 'version_' in dir:\n",
    "            num = int(dir.replace('version_', ''))\n",
    "            if newest_version > num:\n",
    "                continue\n",
    "            \n",
    "            listing = os.listdir(dir_path)\n",
    "            if 'checkpoints' in listing:\n",
    "                check_dir = os.path.join(dir_path, 'checkpoints')\n",
    "                for filename in os.listdir(check_dir):\n",
    "                    if '.ckpt' in filename:\n",
    "                        checkpoint_path = os.path.join(check_dir, filename)\n",
    "                        newest_version = num\n",
    "\n",
    "    print(f'Using checkpoint version {newest_version}!') \n",
    "    return checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4a078ed-1b5a-4a58-8461-020d39ab0641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/macron/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | MuseumCC0Module  | 23.6 M\n",
      "1 | loss_module | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.401    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145d30ab7d0847d4babea095faa4ae18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "config = { \"classes_count\": len(classes) }\n",
    "model = MuseumCC0LightningModule(**config)\n",
    "\n",
    "if not LOAD_LAST_CHECKPOINT:\n",
    "    trainer.fit(model, train_dataloader, test_dataloader)\n",
    "else:\n",
    "    trainer.fit(model, train_dataloader, test_dataloader, ckpt_path=get_newest_model())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410247b-0d73-4b0f-b6d8-1f79054c4399",
   "metadata": {},
   "source": [
    "### Uploading the model to the HuggingFace Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db36ece6-c557-4494-916e-5b6e78641280",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPLOAD_TO_HUGGING_FACE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62456ede-6455-432f-944b-a4cd99e116b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4516bfff6c064534b765ebcb8128de40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/94.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if UPLOAD_TO_HUGGING_FACE:\n",
    "    with open('secrets.json') as f:\n",
    "        data = json.load(f)\n",
    "        HUGGING_FACE_TOKEN = data[\"hugging_face_token\"]\n",
    "    #model.model.save_pretrained(\"cc0-resnet\", config=config)\n",
    "\n",
    "    model.push_to_hub(\"Bulke/cc0-resnet\", config=config, use_auth_token=HUGGING_FACE_TOKEN, private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47fc0d-9155-4d4e-a3fa-489bf095e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.from_pretrained(\"cc0-resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfde53-9333-4733-9729-cbe903dd1148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
